# Decision-Tree-and-Random-Forest

 Random Forest is a method that operates by constructing multiple Decision trees during training phase.

 The decision of the majority of the trees is choosen by the random forest as the final decision.
 
 # In Random Forest 
 
              --> No overfitting. 
              
              --> Training time is less.
              
              --> Uses multiple trees reduce the risk of overfitting.
              
              --> For large datasets when a large portion of the data is missing, but it can maintain good accuracy.
 
            
